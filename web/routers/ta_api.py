import logging
import asyncio
from datetime import datetime, timedelta
from typing import Optional

from fastapi import APIRouter, Request, Form, HTTPException, BackgroundTasks
from fastapi.responses import HTMLResponse, RedirectResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from sqlalchemy import select, desc, text, func

from core.database import AsyncSessionLocal
from core.scheduler import scheduler
from models import Strategy, Trade, Position, StrategyStatus, StrategyType, MarketWatch
from strategies import get_strategy_class, STRATEGY_CLASSES

logger = logging.getLogger(__name__)
templates = Jinja2Templates(directory="web/templates")
router = APIRouter()

@router.post("/api/v1/ta/analyze")
async def api_ta_analyze(request: Request):
    """
    [Agent TA åˆ†ææ¥å£] å¤šæ—¶é—´æ¡†æ¶æŠ€æœ¯åˆ†æ

    æ‰§è¡Œå®Œæ•´çš„å¤šæ—¶é—´æ¡†æ¶ TA åˆ†æï¼Œè¿”å›ä¿¡å·ã€ä¿¡å¿µåˆ†æ•°ã€æ­¢æŸ/æ­¢ç›ˆå’Œå„ç»´åº¦æ˜ç»†ã€‚
    K çº¿æ•°æ®ä¼˜å…ˆä»æœ¬åœ°æ•°æ®åº“è¯»å–ï¼ˆå«è‡ªåŠ¨å¢é‡åŒæ­¥ï¼‰ï¼Œé¦–æ¬¡ä½¿ç”¨æŸ symbol æ—¶ä¼šè‡ªåŠ¨å›å¡«å†å²ã€‚

    è¯·æ±‚ä½“ (JSON):
    {
        "symbol":     "BTC",              # å¸ç§ä»£ç ï¼ˆå¿…å¡«ï¼‰
        "timeframes": ["15m","1h","4h"], # æ—¶é—´æ¡†æ¶ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸‰æ¡†æ¶ï¼‰
        "klines_limit": 300,              # æ¯æ¡†æ¶åŠ è½½ K çº¿æ•°é‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 300ï¼‰
        "buy_threshold":  65,             # BUY è§¦å‘é˜ˆå€¼ï¼ˆå¯é€‰ï¼‰
        "sell_threshold": 35,             # SELL è§¦å‘é˜ˆå€¼ï¼ˆå¯é€‰ï¼‰
        "atr_stop_mult":  2.0,            # ATR æ­¢æŸå€æ•°ï¼ˆå¯é€‰ï¼‰
        "atr_target_mult": 3.0            # ATR æ­¢ç›ˆå€æ•°ï¼ˆå¯é€‰ï¼‰
    }

    å“åº”ä½“:
    {
        "symbol": "BTC",
        "signal": "BUY",          # BUY / SELL / HOLD
        "conviction": 74.5,       # 0-100ï¼Œä¿¡å¿µåˆ†
        "grade": "A",             # A/B/C ä¿¡å·è´¨é‡
        "current_price": 96420.0,
        "stop_loss": 93850.0,
        "take_profit": 101200.0,
        "risk_reward": 1.5,
        "position_size": 0.175,   # å»ºè®®ä»“ä½æ¯”ä¾‹
        "timeframes_used": ["15m","1h","4h"],
        "score_by_tf": {"1h": 72.3, "4h": 78.1, "15m": 65.2},
        "indicators": {           # å„æ—¶é—´æ¡†æ¶æŒ‡æ ‡å¿«ç…§
            "1h": {
                "ema_9":..., "ema_21":..., "ema_50":..., "ema_200":...,
                "rsi":..., "stoch_rsi":{"k":...,"d":...},
                "macd":{"macd_line":..., "signal_line":..., "histogram":..., "cross":...},
                "bollinger":{"upper":...,"lower":...,"percent_b":...},
                "atr":...,
                "volume":{"volume_ratio":...,"trend":...},
                "trend_structure":{"structure":...,"strength":...},
                "candle_patterns":[...]
            }
        },
        "reasons": ["[4h]EMAå¤šå¤´æ’åˆ—", "[1h]MACDé‡‘å‰ğŸŸ¢", ...],
        "analyzed_at": "ISO8601"
    }
    """
    from datetime import timezone
    from strategies.ta_strategy import TAStrategy

    # â”€â”€ è§£æè¯·æ±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        body = await request.json()
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid JSON body")

    symbol = (body.get("symbol") or "BTC").upper().strip()
    timeframes = body.get("timeframes") or ["15m", "1h", "4h"]

    # éªŒè¯æ—¶é—´æ¡†æ¶
    valid_tfs = {"1m", "5m", "15m", "1h", "4h", "1d"}
    invalid = [tf for tf in timeframes if tf not in valid_tfs]
    if invalid:
        raise HTTPException(status_code=400, detail=f"Invalid timeframes: {invalid}. Valid: {sorted(valid_tfs)}")

    # æ„é€ ç­–ç•¥é…ç½®ï¼ˆè¦†ç›–ç”¨æˆ·ä¼ å…¥çš„å‚æ•°ï¼‰
    config = TAStrategy.get_default_config()
    config["symbol"] = symbol
    config["timeframes"] = timeframes
    if "klines_limit" in body:     config["klines_limit"] = int(body["klines_limit"])
    if "buy_threshold" in body:    config["buy_threshold"] = float(body["buy_threshold"])
    if "sell_threshold" in body:   config["sell_threshold"] = float(body["sell_threshold"])
    if "atr_stop_mult" in body:    config["atr_stop_mult"] = float(body["atr_stop_mult"])
    if "atr_target_mult" in body:  config["atr_target_mult"] = float(body["atr_target_mult"])

    # â”€â”€ æ‰§è¡Œåˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        strategy = TAStrategy(config)
        sig = await strategy.analyze()
    except Exception as e:
        logger.error(f"TA analyze error for {symbol}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")

    # â”€â”€ ç»„è£…å“åº”ï¼šä» metadata å–è¯¦ç»†æŒ‡æ ‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    meta = sig.metadata or {}

    # è·å–å„æ—¶é—´æ¡†æ¶æŒ‡æ ‡å¿«ç…§ï¼ˆç²¾ç®€ç‰ˆï¼Œé¿å…å“åº”è¿‡å¤§ï¼‰
    indicators_snapshot = {}
    try:
        from data_collectors.kline_sync import kline_sync
        from indicators.calculator import indicator_calculator as calc

        pair = f"{symbol}USDT"
        async with AsyncSessionLocal() as db:
            tf_data = await kline_sync.get_multi_timeframe_klines(
                db=db, symbol=pair,
                timeframes=timeframes,
                limit=config["klines_limit"],
                sync_first=False,   # å·²ç»åœ¨ analyze() å†…åŒæ­¥è¿‡ï¼Œè¿™é‡Œä¸å†é‡å¤
            )

        for tf, klines in tf_data.items():
            if not klines:
                continue
            ind = calc.calculate_all(klines)
            # åªè¿”å›å…³é”®å­—æ®µï¼ˆå®Œæ•´ klines å¤ªå¤§ï¼‰
            indicators_snapshot[tf] = {
                "current_price": ind.get("current_price"),
                "ema_9":  round(ind.get("ema_9", 0), 2),
                "ema_21": round(ind.get("ema_21", 0), 2),
                "ema_50": round(ind.get("ema_50", 0), 2),
                "ema_200": round(ind.get("ema_200", 0), 2),
                "rsi":    round(ind.get("rsi", 50), 1),
                "stoch_rsi": {
                    "k": round(ind.get("stoch_rsi", {}).get("k", 50), 1),
                    "d": round(ind.get("stoch_rsi", {}).get("d", 50), 1),
                },
                "macd": {
                    "macd_line":   round(ind.get("macd", {}).get("macd_line", 0), 4),
                    "signal_line": round(ind.get("macd", {}).get("signal_line", 0), 4),
                    "histogram":   round(ind.get("macd", {}).get("histogram", 0), 4),
                    "trend":  ind.get("macd", {}).get("trend"),
                    "cross":  ind.get("macd", {}).get("cross"),
                },
                "bollinger": {
                    "upper":     round(ind.get("bollinger", {}).get("upper", 0), 2),
                    "middle":    round(ind.get("bollinger", {}).get("middle", 0), 2),
                    "lower":     round(ind.get("bollinger", {}).get("lower", 0), 2),
                    "percent_b": round(ind.get("bollinger", {}).get("percent_b", 0.5), 3),
                    "squeeze":   ind.get("bollinger", {}).get("squeeze", False),
                },
                "atr": round(ind.get("atr", 0), 2),
                "volume": {
                    "volume_ratio": round(ind.get("volume", {}).get("volume_ratio", 1), 2),
                    "trend":        ind.get("volume", {}).get("trend"),
                },
                "trend_structure": {
                    "structure": ind.get("trend_structure", {}).get("structure"),
                    "strength":  round(ind.get("trend_structure", {}).get("strength", 50), 1),
                },
                "candle_patterns": ind.get("candle_patterns", []),
            }
    except Exception as e:
        logger.warning(f"Failed to build indicators snapshot: {e}")

    # â”€â”€ è·å–å®æ—¶ä»·æ ¼ï¼ˆè¦†ç›–Kçº¿æ”¶ç›˜ä»·ï¼Œé¿å…ä»·æ ¼æ»åï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # current_price æ¥è‡ª closes[-1]ï¼Œå³æœ€è¿‘ä¸€æ ¹å·²é—­åˆKçº¿çš„æ”¶ç›˜ä»·ï¼Œ
    # å¯èƒ½æ¯”å®æ—¶ä»·æ ¼æ»å 1 ä¸ªKçº¿å‘¨æœŸï¼ˆå¦‚ 1h æ—¶å¯èƒ½æ»å ~1å°æ—¶ï¼‰ã€‚
    # è¿™é‡Œé¢å¤–è°ƒç”¨ Binance ticker è·å–å®æ—¶ä»·æ ¼æ¥è¦†ç›–å®ƒã€‚
    live_price = meta.get("current_price")  # é»˜è®¤å›é€€åˆ°Kçº¿ä»·æ ¼
    try:
        from data_collectors import binance_collector
        ticker_live = await binance_collector.get_24h_ticker(f"{symbol}USDT")
        if ticker_live and ticker_live.get("price"):
            live_price = ticker_live["price"]
    except Exception as e_price:
        logger.warning(f"Failed to fetch live price for {symbol}, using kline close: {e_price}")

    return {
        "symbol":         symbol,
        "signal":         sig.signal.value.upper(),
        "conviction":     sig.conviction_score,
        "grade":          meta.get("grade", "B"),
        "current_price":  live_price,
        "stop_loss":      sig.stop_loss,
        "take_profit":    sig.take_profit,
        "risk_reward":    meta.get("risk_reward"),
        "position_size":  sig.position_size,
        "atr":            meta.get("atr"),
        "timeframes_used": timeframes,
        "score_by_tf":    meta.get("score_by_tf", {}),
        "indicators":     indicators_snapshot,
        "reasons":        sig.reason.split("; ") if sig.reason else [],
        "analyzed_at":    datetime.now(timezone.utc).isoformat(),
    }

@router.get("/api/v1/ta/klines-status")
async def api_ta_klines_status():
    """
    K çº¿æœ¬åœ°æ•°æ®åº“è¦†ç›–æƒ…å†µæŸ¥è¯¢

    è¿”å›å„ symbol/timeframe åœ¨æœ¬åœ°æ•°æ®åº“ä¸­çš„æ•°æ®æ¡æ•°å’Œæ—¶é—´èŒƒå›´ã€‚
    ç”¨äºç¡®è®¤æ•°æ®æ˜¯å¦å·²ç»å›å¡«å®Œæˆã€‚
    """
    from models.kline_cache import KlineCache
    from sqlalchemy import func
    from datetime import timezone

    async with AsyncSessionLocal() as db:
        result = await db.execute(
            select(
                KlineCache.symbol,
                KlineCache.interval,
                func.count(KlineCache.id).label("count"),
                func.min(KlineCache.open_time).label("oldest_ms"),
                func.max(KlineCache.open_time).label("newest_ms"),
            ).group_by(KlineCache.symbol, KlineCache.interval)
            .order_by(KlineCache.symbol, KlineCache.interval)
        )
        rows = result.all()

    status = []
    for row in rows:
        oldest = datetime.fromtimestamp(row.oldest_ms / 1000, tz=timezone.utc).isoformat() if row.oldest_ms else None
        newest = datetime.fromtimestamp(row.newest_ms / 1000, tz=timezone.utc).isoformat() if row.newest_ms else None
        status.append({
            "symbol":   row.symbol,
            "interval": row.interval,
            "count":    row.count,
            "oldest":   oldest,
            "newest":   newest,
        })

    return {"klines_db_status": status, "total_entries": sum(r["count"] for r in status)}

